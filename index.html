<!doctype html>
<html>

<head>
  <title>JackRL</title>
  <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">
  <link href="css/frame.css" media="screen" rel="stylesheet" type="text/css" />
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <style>
    .menu-index {
      color: rgb(255, 255, 255) !important;
      opacity: 1 !important;
      font-weight: 700 !important;
    }
  </style>
</head>

<body>
  <div class="menu-container"></div>
  <div class="content-container">
    <div class="content">
      <div class="content-table flex-column">
        <!--Start Intro-->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <img class="image" src="img/blackjack.jpg">
           	<h1 class="add-top-margin"><b>JackRL</b></h2>
           	A reinforcement learning-driven agent for blackjack.
          </div>
          <div class="flex-item flex-column">
            <p class="text text-large">
              <b>Bryce Blanton</b>, bblanton (at) uci (dot) edu<br>
              <b>Trevor Nelson</b>, trevorjn (at) uci (dot) edu<br>
              <b>Raghav Verma</b>, raghavv (at) uci (dot) edu<br><br>
              <b>University of California, Irvine</b><br>
            </p>
          </div>
        </div>
        <!--End Intro-->
        <!--Start Description-->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">Summary</h2>
            <hr>
            <p class="text">
              The goal of this project is to make a reinforcement learning agent for simplified blackjack. This version of blackjack will not allow doubling down nor splitting. Furthermore, we will only use a single deck of cards each game. The input of the agent will be the state of the game represented by a list of the players’ and the house's current cards. It will output the next decision that it expects will maximize its winnings. We will be simulating the game environment. One possible application is a blackjack game engine, which could be used to analyze games or improve one’s play.
            </p>
            <h2 class="add-top-margin">Evaluation Plan</h2>
            <hr>
            <p class="text">
				The success of our project will be measured primarily by the agent’s average winnings in a game of blackjack. We will consider average winnings as the metric for determining how well it performs. An agent which makes random decisions will act as the baseline against which our agent is compared. We expect to improve the win rate from about 0% to about 49%, which is the win rate for an optimal player who does not count cards.<br><br>

				We will ensure a basic level of competency with sanity cases representing situations with an obviously correct decision. One example is when the agent’s hand value is low enough that no hit could possibly result in a bust. We can visualize the learning process by monitoring the average winnings over time. Our moonshot goal is to train an agent to make a decision which is likely to earn a profit, but would be incorrect according to the basic strategy of blackjack. This would indicate that the agent can use the observed cards of other players to improve its decision making (i.e. count cards). This is the only way our agent can achieve a net profit over an arbitrarily large set of games.
            </p>
            <h2 class="add-top-margin">Goals</h2>
            <hr>
            <p class="text">
				Minimum: Better than a random agent
				<ul>
					<li>Milestone 1: Write the logic for blackjack and a random agent, and then simulate and score the random agent.</li>
					<li>Milestone 2: Achieve a win rate higher than the random agent.</li>
				</ul>
				Realistic: Optimal play without card counting
				<ul>
					<li>Milestone 1: Achieve a win rate of at least 25%.</li>
					<li>Milestone 2: Achieve a net profit of approximately $0 (49-49.5%).</li>
				</ul>
				Ambitious: Significantly better play than an optimal agent/”the house” (i.e. card counting)
				<ul>
					<li>Milestone: The agent makes a net profit over hundreds/thousands of hands.</li>
				</ul>
            </p>
          </div>
        </div>
        <!--End Description-->
        <!--Start Credits-->
        <div class="flex-row">
          <div class="flex-item flex-item-stretch flex-column">
            <p class="text text-small text-italic">
              Theme by <a href="https://github.com/yenchiah/project-website-template"><span class="highlight-text">Yen-Chia Hsu</span></a>
            </p>
          </div>
        </div>
        <!--End Credits-->
      </div>
    </div>
  </div>
</body>

</html>